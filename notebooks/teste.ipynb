{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.recruitai import RecruitAI  # noqa: E402\n",
    "\n",
    "# Find env vars.\n",
    "load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruit_ai = RecruitAI(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requisitos:\n",
      "Requerimentos vem aqui\n",
      "\n",
      "Currículo do Candidato:\n",
      "O curriculo vem aqui\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = recruit_ai.get_prompt(\"Requerimentos vem aqui\", \"O curriculo vem aqui\")\n",
    "print(r[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculum = recruit_ai.get_text_from_pdf(\"/home/cayena/Downloads/curriculo.pdf\")\n",
    "vaga = recruit_ai.get_text_from_pdf(\"/home/cayena/Downloads/vaga.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bacharel em Química e doutorando em Química Computacional pela Universidade de São Paulo.\n",
      "Atualmente atuo como cientista de dados Jr na empresa Cayena.\n",
      "Linguagens de Programação: Python, Bash e SQL.\n",
      "Banco de dados: MySQL e PostgreSQL.\n",
      "Banco de dados NoSQL: Redis, elasticsearch e meilisearch.\n",
      "Manipulação númerica e de dados: Pandas, Koalas e Numpy.\n",
      "Visualização de dados: Matplotlib, Plotly e Seaborn.\n",
      "Machine Learning : Scikit-Learn.\n",
      "Deep Learning: Keras e Pytroch. \n",
      "MLOps: MLFlow e ClearML.\n",
      "Versionamento de código: Git.\n",
      "Cloud: AWS (S3, lambda, Redshift e etc.)\n",
      "Outros: Docker e langchain.\n",
      "Repositório do GitHub: https://github.com/ramoonmedeiro\n",
      "Perfil na plataforma BeeCrowd: https://www.beecrowd.com.br/judge/pt/profile/438637\n",
      "Perfil no HuggingFace: https://huggingface.co/ramonmedeiro1\n"
     ]
    }
   ],
   "source": [
    "print(curriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somos especialistas digitais e impactamos as marcas mais valiosas do mundo. Construímos\n",
      "produtos e soluções digitais focados nas necessidades dos nossos clientes. Como uma nativa\n",
      "digital, trazemos um histórico de 28 anos de aceleração do impacto nos negócios por meio de\n",
      "soluções digitais completas e escaláveis. Com uma presença global de mais de 6.500 pessoas em\n",
      "estratégia, pesquisa, ciência de dados, design e engenharia, desbloqueamos o crescimento de\n",
      "primeira linha, melhoramos a experiência do cliente e impulsionamos a eficiência operacional.\n",
      "Sua Missão\n",
      "Ajudar o cliente a automatizar processos financeiros, garantindo eficiência e segurança em cada\n",
      "etapa. O objetivo é usar NLP (Processamento de Linguagem Natural) para interpretação de textos\n",
      "extraídos de documentos, correlacionar com códigos específicos garantindo um alto percentual de\n",
      "acurácia. Para este papel será necessário interação frequente com o cliente para definição das\n",
      "regras de negócio, deverá trabalhar com grandes volumes de dados e ter autonomia para\n",
      "interpretar os dados e propor novas soluções para a área com o foco em reduzir processos\n",
      "manuais e aumentar a segurança.\n",
      "Você Precisa Ter Prática Com\n",
      "Análise Exploratória de Dados: criar narrativas baseadas em dados para apresentar o resultado das\n",
      "análises, treinar e avaliar de modelos de NLP. Programação, manipulação e modelagem de dados\n",
      "em Python/Spark/SQL.#Midsenior\n",
      "CI&T é uma empresa que oferece oportunidades iguais. Celebramos e valorizamos a diversidade\n",
      "de identidades e experiências vividas de nossos CI&Ters. Estamos empenhados em construir,\n",
      "promover e manter uma empresa e cultura diversificada, inclusiva e equitativa focada em criar um\n",
      "amanhã melhor.\n",
      "Na CI&T, reconhecemos que inovação e transformação só acontecem em ambientes de trabalho\n",
      "diversificados, inclusivos e seguros. Nossas equipes são mais impactantes quando pessoas de\n",
      "todas as formações e experiências colaboram para compartilhar, criar e ouvir ideias.\n",
      "Incentivamos fortemente pessoas de comunidades diversas e sub-representadas a se\n",
      "candidatarem às nossas vagas.\n"
     ]
    }
   ],
   "source": [
    "print(vaga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = recruit_ai.get_prompt(vaga, curriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Você é o melhor recrutador de todos os tempos. Você está analisando um currículo de um candidato para uma vaga de emprego.\n",
      "Por mais que esta instrução esteja em português, você pode receber um currículo em outra língua que não seja\n",
      "português ou inglês, com isso, ao final, você deve gerar os resultados em inglês sempre.\n",
      "Esta vaga poderá ser de diversas áreas e para diversos cargos.\n",
      "Você deve exclusivamente se basear nos requisitos passados abaixo. Os requisitos poderão ser a própria descrição da vaga\n",
      "ou algumas exigências que o candidato deve ter para ocupar a vaga ou ambos.\n",
      "Primeiro, você deve criar uma etapa fazendo um resumo das qualidades do candidato e destacar pontos que são de extremo\n",
      "interesse da vaga. Após a etapa anterior, você deve dar pontuações para cada característica que você observar no currículo do\n",
      "candidato e dar uma pontuação de 0 a 10, sendo 0 para o candidato que não atende a característica e 10 para o candidato que atende perfeitamente \n",
      "a característica. Pode ser que o currículo tenha caracterísiticas a mais do que é pedido, se esses requisitos forem interessantes\n",
      "para a vaga, vale a pena destacar esses pontos.\n",
      "Ao final, você deverá dar uma nota final geral (também entre 0 a 10) deste candidato se baseando nas pontuações anteriores.\n",
      "\n",
      "O resultado deve ser da forma:\n",
      "\n",
      "Nome do Candidato: Resumo do candidato.\n",
      "\n",
      "Requisitos:\n",
      "As notas para cada requisito irão vir aqui.\n",
      "\n",
      "Resultado Final:\n",
      "Nota geral final irá vir aqui.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requisitos:\n",
      "Somos especialistas digitais e impactamos as marcas mais valiosas do mundo. Construímos\n",
      "produtos e soluções digitais focados nas necessidades dos nossos clientes. Como uma nativa\n",
      "digital, trazemos um histórico de 28 anos de aceleração do impacto nos negócios por meio de\n",
      "soluções digitais completas e escaláveis. Com uma presença global de mais de 6.500 pessoas em\n",
      "estratégia, pesquisa, ciência de dados, design e engenharia, desbloqueamos o crescimento de\n",
      "primeira linha, melhoramos a experiência do cliente e impulsionamos a eficiência operacional.\n",
      "Sua Missão\n",
      "Ajudar o cliente a automatizar processos financeiros, garantindo eficiência e segurança em cada\n",
      "etapa. O objetivo é usar NLP (Processamento de Linguagem Natural) para interpretação de textos\n",
      "extraídos de documentos, correlacionar com códigos específicos garantindo um alto percentual de\n",
      "acurácia. Para este papel será necessário interação frequente com o cliente para definição das\n",
      "regras de negócio, deverá trabalhar com grandes volumes de dados e ter autonomia para\n",
      "interpretar os dados e propor novas soluções para a área com o foco em reduzir processos\n",
      "manuais e aumentar a segurança.\n",
      "Você Precisa Ter Prática Com\n",
      "Análise Exploratória de Dados: criar narrativas baseadas em dados para apresentar o resultado das\n",
      "análises, treinar e avaliar de modelos de NLP. Programação, manipulação e modelagem de dados\n",
      "em Python/Spark/SQL.#Midsenior\n",
      "CI&T é uma empresa que oferece oportunidades iguais. Celebramos e valorizamos a diversidade\n",
      "de identidades e experiências vividas de nossos CI&Ters. Estamos empenhados em construir,\n",
      "promover e manter uma empresa e cultura diversificada, inclusiva e equitativa focada em criar um\n",
      "amanhã melhor.\n",
      "Na CI&T, reconhecemos que inovação e transformação só acontecem em ambientes de trabalho\n",
      "diversificados, inclusivos e seguros. Nossas equipes são mais impactantes quando pessoas de\n",
      "todas as formações e experiências colaboram para compartilhar, criar e ouvir ideias.\n",
      "Incentivamos fortemente pessoas de comunidades diversas e sub-representadas a se\n",
      "candidatarem às nossas vagas.\n",
      "\n",
      "Currículo do Candidato:\n",
      "Bacharel em Química e doutorando em Química Computacional pela Universidade de São Paulo.\n",
      "Atualmente atuo como cientista de dados Jr na empresa Cayena.\n",
      "Linguagens de Programação: Python, Bash e SQL.\n",
      "Banco de dados: MySQL e PostgreSQL.\n",
      "Banco de dados NoSQL: Redis, elasticsearch e meilisearch.\n",
      "Manipulação númerica e de dados: Pandas, Koalas e Numpy.\n",
      "Visualização de dados: Matplotlib, Plotly e Seaborn.\n",
      "Machine Learning : Scikit-Learn.\n",
      "Deep Learning: Keras e Pytroch. \n",
      "MLOps: MLFlow e ClearML.\n",
      "Versionamento de código: Git.\n",
      "Cloud: AWS (S3, lambda, Redshift e etc.)\n",
      "Outros: Docker e langchain.\n",
      "Repositório do GitHub: https://github.com/ramoonmedeiro\n",
      "Perfil na plataforma BeeCrowd: https://www.beecrowd.com.br/judge/pt/profile/438637\n",
      "Perfil no HuggingFace: https://huggingface.co/ramonmedeiro1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = recruit_ai.llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate's Name: Ramon Medeiro\n",
      "\n",
      "Candidate Summary:\n",
      "Ramon Medeiro is a Junior Data Scientist with a background in Chemistry and currently pursuing a Ph.D. in Computational Chemistry at the University of São Paulo. He has experience working with Python, Bash, and SQL programming languages, as well as MySQL and PostgreSQL databases. Ramon is skilled in data manipulation and analysis using Pandas, Koalas, and Numpy, and has knowledge of data visualization tools such as Matplotlib, Plotly, and Seaborn. He also has experience with machine learning using Scikit-Learn, deep learning frameworks like Keras and Pytorch, and MLOps tools such as MLFlow and ClearML. Ramon is familiar with version control using Git and has worked with cloud platforms like AWS. He is also proficient in Docker and langchain. Ramon has a strong online presence, with a GitHub repository, a profile on the BeeCrowd platform, and a profile on HuggingFace.\n",
      "\n",
      "Requirements:\n",
      "- Data Analysis: Ramon has experience in data manipulation, analysis, and creating data-driven narratives.\n",
      "- NLP Modeling: Although not explicitly mentioned in the candidate's summary, Ramon's experience with Python and deep learning frameworks like Keras and Pytorch suggests he has the skills required for NLP modeling.\n",
      "- Programming Skills: Ramon is proficient in Python, Bash, and SQL, which are essential programming languages for this role.\n",
      "- Database Knowledge: Ramon has experience working with MySQL and PostgreSQL databases, which are relevant for the position.\n",
      "- Data Manipulation: Ramon is skilled in data manipulation using Pandas, Koalas, and Numpy, which is crucial for working with large volumes of data.\n",
      "- Data Visualization: Ramon has experience with data visualization tools such as Matplotlib, Plotly, and Seaborn, which can be valuable for presenting analysis results.\n",
      "- Machine Learning: Ramon has experience with machine learning using Scikit-Learn, which is relevant for developing models in this role.\n",
      "- Deep Learning: Ramon has knowledge of deep learning frameworks like Keras and Pytorch, which can be beneficial for advanced NLP tasks.\n",
      "- MLOps: Ramon has experience with MLOps tools like MLFlow and ClearML, which can contribute to the automation and efficiency of the financial processes.\n",
      "- Version Control: Ramon is familiar with Git, which is essential for collaborative development and version control.\n",
      "- Cloud Experience: Ramon has worked with AWS, including services like S3, Lambda, and Redshift, which aligns with the requirement of working with large volumes of data and proposing new solutions.\n",
      "- Other Skills: Ramon's knowledge of Docker and langchain can be advantageous for deploying and managing applications.\n",
      "\n",
      "Final Result:\n",
      "Based on the candidate's qualifications and experience, Ramon Medeiro is a strong candidate for the position, meeting most of the requirements and demonstrating expertise in relevant areas. The overall rating for Ramon is 9 out of 10.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Candidate's Name: Ramon Medeiro\n",
    "\n",
    "Candidate Summary:\n",
    "Ramon Medeiro is a Junior Data Scientist with a background in Chemistry and currently pursuing a Ph.D. in Computational Chemistry at the University of São Paulo. He has experience working with Python, Bash, and SQL programming languages, as well as MySQL and PostgreSQL databases. Ramon is skilled in data manipulation and analysis using Pandas, Koalas, and Numpy, and has knowledge of data visualization tools such as Matplotlib, Plotly, and Seaborn. He also has experience with machine learning using Scikit-Learn, deep learning frameworks like Keras and Pytorch, and MLOps tools such as MLFlow and ClearML. Ramon is familiar with version control using Git and has worked with cloud platforms like AWS. He is also proficient in Docker and langchain. Ramon has a strong online presence, with a GitHub repository, a profile on the BeeCrowd platform, and a profile on HuggingFace.\n",
    "\n",
    "Requirements:\n",
    "- Data Analysis: Ramon has experience in data manipulation, analysis, and creating data-driven narratives.\n",
    "- NLP Modeling: Although not explicitly mentioned in the candidate's summary, Ramon's experience with Python and deep learning frameworks like Keras and Pytorch suggests he has the skills required for NLP modeling.\n",
    "- Programming Skills: Ramon is proficient in Python, Bash, and SQL, which are essential programming languages for this role.\n",
    "- Database Knowledge: Ramon has experience working with MySQL and PostgreSQL databases, which are relevant for the position.\n",
    "- Data Manipulation: Ramon is skilled in data manipulation using Pandas, Koalas, and Numpy, which is crucial for working with large volumes of data.\n",
    "- Data Visualization: Ramon has experience with data visualization tools such as Matplotlib, Plotly, and Seaborn, which can be valuable for presenting analysis results.\n",
    "- Machine Learning: Ramon has experience with machine learning using Scikit-Learn, which is relevant for developing models in this role.\n",
    "- Deep Learning: Ramon has knowledge of deep learning frameworks like Keras and Pytorch, which can be beneficial for advanced NLP tasks.\n",
    "- MLOps: Ramon has experience with MLOps tools like MLFlow and ClearML, which can contribute to the automation and efficiency of the financial processes.\n",
    "- Version Control: Ramon is familiar with Git, which is essential for collaborative development and version control.\n",
    "- Cloud Experience: Ramon has worked with AWS, including services like S3, Lambda, and Redshift, which aligns with the requirement of working with large volumes of data and proposing new solutions.\n",
    "- Other Skills: Ramon's knowledge of Docker and langchain can be advantageous for deploying and managing applications.\n",
    "\n",
    "Final Result:\n",
    "Based on the candidate's qualifications and experience, Ramon Medeiro is a strong candidate for the position, meeting most of the requirements and demonstrating expertise in relevant areas. The overall rating for Ramon is 9 out of 10.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_final = recruit_ai.text2pdf(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x7fba5635ea70>\n"
     ]
    }
   ],
   "source": [
    "print(pdf_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-QQIxkt6l-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
